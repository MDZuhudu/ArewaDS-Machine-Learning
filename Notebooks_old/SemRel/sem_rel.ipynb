{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__MACOSX',\n",
       " 'Semantic Textual Relatedness (STR) - SemEval 2024 Task 1 (Evaluation Phase)-16799-results-4']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since the initial attempt to process the files did not yield the expected results,\n",
    "# let's start over by simply unzipping the main uploaded file again to verify its contents.\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# Path to the uploaded zip file\n",
    "zip_file_path = \"./Semantic Textual Relatedness (STR) - SemEval 2024 Task 1 (Evaluation Phase)-16799-results-4.zip\"\n",
    "# Define a new extraction directory to start fresh\n",
    "extraction_dir_fresh = './Output/'\n",
    "\n",
    "# Unzip the uploaded file\n",
    "with ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extraction_dir_fresh)\n",
    "\n",
    "# List all files and directories in the new unzipped directory to verify the contents\n",
    "unzipped_contents_fresh = os.listdir(extraction_dir_fresh)\n",
    "unzipped_contents_fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the extraction directory path\n",
    "extraction_dir = './output/'\n",
    "\n",
    "# Define the main folder path again\n",
    "unzipped_contents = os.listdir(extraction_dir)\n",
    "main_folder = [d for d in unzipped_contents if not d.startswith('__')][0]\n",
    "main_folder_path = os.path.join(extraction_dir, main_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Team MBZUAI-UNAM  - 1 output.zip',\n",
       " 'Team Pinealai  - 1 output.zip',\n",
       " 'msiino - 2 output.zip',\n",
       " 'Team INGEOTEC  - 1 output.zip',\n",
       " 'Team BpHigh  - 1 output.zip',\n",
       " 'Team VerbaNexAI Lab  - 3 output.zip',\n",
       " 'Team Fired_from_NLP  - 2 output.zip',\n",
       " 'LuisRamos07 - 1 output.zip',\n",
       " 'Team IITK  - 2 output.zip',\n",
       " 'Team NRK  - 1 output.zip',\n",
       " 'Team OZemi  - 1 output.zip',\n",
       " 'Team UAlbertaNLP  - 2 output.zip',\n",
       " 'Team Text Mining  - 1 output.zip',\n",
       " 'Team AAdaM  - 2 output.zip',\n",
       " 'Team YNUNLP2023  - 1 output.zip',\n",
       " 'Team MasonTigers  - 1 output.zip',\n",
       " 'Team YSP  - 1 output.zip',\n",
       " 'Team NLP_STR_teamS  - 1 output.zip',\n",
       " 'Team PALI  - 2 output.zip',\n",
       " 'Team NLP-LISAC  - 3 output.zip',\n",
       " 'Team KINLP  - 1 output.zip',\n",
       " 'Team HausaNLP  - 1 output.zip',\n",
       " 'Team Unknown  - 2 output.zip',\n",
       " 'Team WarwickNLP  - 2 output.zip',\n",
       " 'Team GIL-IIMAS UNAM  - 1 output.zip',\n",
       " 'Team UMBCLU  - 1 output.zip',\n",
       " 'Team team triplet  - 2 output.zip',\n",
       " 'Team king001  - 2 output.zip',\n",
       " 'Team NLP_Team1@SSN  - 3 output.zip',\n",
       " 'Roronoa_Zoro - 3 output.zip',\n",
       " 'Team silp_nlp  - 1 output.zip',\n",
       " 'Team BITS Pilani  - 1 output.zip',\n",
       " 'Team SemanticCUETSync  - 1 output.zip',\n",
       " 'Team Sharif_STR  - 2 output.zip',\n",
       " 'Team Tu╠êbingen-CL  - 1 output.zip',\n",
       " 'Team CAILMD-23  - 1 output.zip']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all files and directories in the main folder again\n",
    "main_folder_contents = os.listdir(main_folder_path)\n",
    "\n",
    "\n",
    "\n",
    "# Filter for zip files that contain the word \"output\" in their names\n",
    "output_zip_files = [f for f in main_folder_contents if f.endswith('.zip') and 'output' in f.lower()]\n",
    "output_zip_files_paths = [os.path.join(main_folder_path, f) for f in output_zip_files]\n",
    "\n",
    "# Extract the names for confirmation\n",
    "output_zip_files_names = [os.path.basename(path) for path in output_zip_files_paths]\n",
    "output_zip_files_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Team MBZUAI-UNAM  - 1 output.zip',\n",
       " 'Team Pinealai  - 1 output.zip',\n",
       " 'msiino - 2 output.zip',\n",
       " 'Team INGEOTEC  - 1 output.zip',\n",
       " 'Team BpHigh  - 1 output.zip',\n",
       " 'Team VerbaNexAI Lab  - 3 output.zip',\n",
       " 'Team Fired_from_NLP  - 2 output.zip',\n",
       " 'LuisRamos07 - 1 output.zip',\n",
       " 'Team IITK  - 2 output.zip',\n",
       " 'Team NRK  - 1 output.zip',\n",
       " 'Team OZemi  - 1 output.zip',\n",
       " 'Team UAlbertaNLP  - 2 output.zip',\n",
       " 'Team Text Mining  - 1 output.zip',\n",
       " 'Team AAdaM  - 2 output.zip',\n",
       " 'Team YNUNLP2023  - 1 output.zip',\n",
       " 'Team MasonTigers  - 1 output.zip',\n",
       " 'Team YSP  - 1 output.zip',\n",
       " 'Team NLP_STR_teamS  - 1 output.zip',\n",
       " 'Team PALI  - 2 output.zip',\n",
       " 'Team NLP-LISAC  - 3 output.zip',\n",
       " 'Team KINLP  - 1 output.zip',\n",
       " 'Team HausaNLP  - 1 output.zip',\n",
       " 'Team Unknown  - 2 output.zip',\n",
       " 'Team WarwickNLP  - 2 output.zip',\n",
       " 'Team GIL-IIMAS UNAM  - 1 output.zip',\n",
       " 'Team UMBCLU  - 1 output.zip',\n",
       " 'Team team triplet  - 2 output.zip',\n",
       " 'Team king001  - 2 output.zip',\n",
       " 'Team NLP_Team1@SSN  - 3 output.zip',\n",
       " 'Roronoa_Zoro - 3 output.zip',\n",
       " 'Team silp_nlp  - 1 output.zip',\n",
       " 'Team BITS Pilani  - 1 output.zip',\n",
       " 'Team SemanticCUETSync  - 1 output.zip',\n",
       " 'Team Sharif_STR  - 2 output.zip',\n",
       " 'Team Tu╠êbingen-CL  - 1 output.zip',\n",
       " 'Team CAILMD-23  - 1 output.zip']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since the execution state was reset and the previous paths are not available, we need to redo the steps to identify the zip files with \"output\" in their names.\n",
    "\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# Redefine initial zip file path and extraction directory\n",
    "zip_file_path = './Semantic Textual Relatedness (STR) - SemEval 2024 Task 1 (Evaluation Phase)-16799-results-4.zip'\n",
    "extraction_dir = './output/'\n",
    "\n",
    "# Unzip the uploaded file again\n",
    "with ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extraction_dir)\n",
    "\n",
    "# Define the main folder path again\n",
    "extraction_dir = './output/'  # Update the extraction_dir to a valid directory path\n",
    "unzipped_contents = os.listdir(extraction_dir)\n",
    "main_folder = [d for d in unzipped_contents if not d.startswith('__')][0]\n",
    "main_folder_path = os.path.join(extraction_dir, main_folder)\n",
    "\n",
    "# List all files and directories in the main folder again\n",
    "main_folder_contents = os.listdir(main_folder_path)\n",
    "\n",
    "\n",
    "# Filter for zip files that contain the word \"output\" in their names\n",
    "output_zip_files = [f for f in main_folder_contents if f.endswith('.zip') and 'output' in f.lower()]\n",
    "output_zip_files_paths = [os.path.join(main_folder_path, f) for f in output_zip_files]\n",
    "\n",
    "# Extract the names for confirmation\n",
    "output_zip_files_names = [os.path.basename(path) for path in output_zip_files_paths]\n",
    "output_zip_files_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Name</th>\n",
       "      <th>Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Team MBZUAI-UNAM  - 1 output</td>\n",
       "      <td>0.831625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Team Pinealai  - 1 output</td>\n",
       "      <td>0.837163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>msiino - 2 output</td>\n",
       "      <td>0.808586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Team INGEOTEC  - 1 output</td>\n",
       "      <td>0.808650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Team BpHigh  - 1 output</td>\n",
       "      <td>0.808866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Team VerbaNexAI Lab  - 3 output</td>\n",
       "      <td>0.819189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Team Fired_from_NLP  - 2 output</td>\n",
       "      <td>0.810334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LuisRamos07 - 1 output</td>\n",
       "      <td>0.822289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Team IITK  - 2 output</td>\n",
       "      <td>0.808445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Team NRK  - 1 output</td>\n",
       "      <td>0.832901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Team OZemi  - 1 output</td>\n",
       "      <td>0.805227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Team UAlbertaNLP  - 2 output</td>\n",
       "      <td>0.853192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Team Text Mining  - 1 output</td>\n",
       "      <td>0.720198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Team AAdaM  - 2 output</td>\n",
       "      <td>0.848436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Team YNUNLP2023  - 1 output</td>\n",
       "      <td>0.557246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Team MasonTigers  - 1 output</td>\n",
       "      <td>0.835603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Team YSP  - 1 output</td>\n",
       "      <td>0.819434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Team NLP_STR_teamS  - 1 output</td>\n",
       "      <td>0.809450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Team PALI  - 2 output</td>\n",
       "      <td>0.859576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Team NLP-LISAC  - 3 output</td>\n",
       "      <td>0.834584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Team KINLP  - 1 output</td>\n",
       "      <td>0.740003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Team HausaNLP  - 1 output</td>\n",
       "      <td>0.794372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Team Unknown  - 2 output</td>\n",
       "      <td>0.830615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Team WarwickNLP  - 2 output</td>\n",
       "      <td>0.842469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Team GIL-IIMAS UNAM  - 1 output</td>\n",
       "      <td>0.830448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Team UMBCLU  - 1 output</td>\n",
       "      <td>0.838050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Team team triplet  - 2 output</td>\n",
       "      <td>0.847886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Team king001  - 2 output</td>\n",
       "      <td>0.843086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Team NLP_Team1@SSN  - 3 output</td>\n",
       "      <td>0.835241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Roronoa_Zoro - 3 output</td>\n",
       "      <td>0.809767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Team silp_nlp  - 1 output</td>\n",
       "      <td>0.844622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Team BITS Pilani  - 1 output</td>\n",
       "      <td>0.832374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Team SemanticCUETSync  - 1 output</td>\n",
       "      <td>0.822186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Team Sharif_STR  - 2 output</td>\n",
       "      <td>0.827404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Team Tu╠êbingen-CL  - 1 output</td>\n",
       "      <td>0.849975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Team CAILMD-23  - 1 output</td>\n",
       "      <td>0.823047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            File Name  Spearman Correlation\n",
       "0        Team MBZUAI-UNAM  - 1 output              0.831625\n",
       "1           Team Pinealai  - 1 output              0.837163\n",
       "2                   msiino - 2 output              0.808586\n",
       "3           Team INGEOTEC  - 1 output              0.808650\n",
       "4             Team BpHigh  - 1 output              0.808866\n",
       "5     Team VerbaNexAI Lab  - 3 output              0.819189\n",
       "6     Team Fired_from_NLP  - 2 output              0.810334\n",
       "7              LuisRamos07 - 1 output              0.822289\n",
       "8               Team IITK  - 2 output              0.808445\n",
       "9                Team NRK  - 1 output              0.832901\n",
       "10             Team OZemi  - 1 output              0.805227\n",
       "11       Team UAlbertaNLP  - 2 output              0.853192\n",
       "12       Team Text Mining  - 1 output              0.720198\n",
       "13             Team AAdaM  - 2 output              0.848436\n",
       "14        Team YNUNLP2023  - 1 output              0.557246\n",
       "15       Team MasonTigers  - 1 output              0.835603\n",
       "16               Team YSP  - 1 output              0.819434\n",
       "17     Team NLP_STR_teamS  - 1 output              0.809450\n",
       "18              Team PALI  - 2 output              0.859576\n",
       "19         Team NLP-LISAC  - 3 output              0.834584\n",
       "20             Team KINLP  - 1 output              0.740003\n",
       "21          Team HausaNLP  - 1 output              0.794372\n",
       "22           Team Unknown  - 2 output              0.830615\n",
       "23        Team WarwickNLP  - 2 output              0.842469\n",
       "24    Team GIL-IIMAS UNAM  - 1 output              0.830448\n",
       "25            Team UMBCLU  - 1 output              0.838050\n",
       "26      Team team triplet  - 2 output              0.847886\n",
       "27           Team king001  - 2 output              0.843086\n",
       "28     Team NLP_Team1@SSN  - 3 output              0.835241\n",
       "29            Roronoa_Zoro - 3 output              0.809767\n",
       "30          Team silp_nlp  - 1 output              0.844622\n",
       "31       Team BITS Pilani  - 1 output              0.832374\n",
       "32  Team SemanticCUETSync  - 1 output              0.822186\n",
       "33        Team Sharif_STR  - 2 output              0.827404\n",
       "34     Team Tu╠êbingen-CL  - 1 output              0.849975\n",
       "35         Team CAILMD-23  - 1 output              0.823047"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize a list to store the extracted data\n",
    "data = []\n",
    "\n",
    "# Function to extract spearman_cor from scores.txt\n",
    "def extract_spearman_cor_from_scores(extracted_dir):\n",
    "    scores_path = os.path.join(extracted_dir, 'scores.txt')\n",
    "    try:\n",
    "        with open(scores_path, 'r') as file:\n",
    "            for line in file:\n",
    "                if 'spearman_cor' in line:\n",
    "                    return float(line.split(':')[-1].strip())\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "# Iterate over the selected zip files, unzip them, and extract the spearman_cor value\n",
    "for zip_path in output_zip_files_paths:\n",
    "    # Define a directory based on the zip file's name to extract its contents\n",
    "    extracted_dir_path = zip_path.replace('.zip', '_extracted')\n",
    "    \n",
    "    # Unzip the file into the defined directory\n",
    "    with ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extracted_dir_path)\n",
    "    \n",
    "    # Extract the spearman_cor value\n",
    "    spearman_cor = extract_spearman_cor_from_scores(extracted_dir_path)\n",
    "    \n",
    "    # Add the filename (without path and extension) and spearman_cor to the data list\n",
    "    file_name = os.path.basename(zip_path).replace('.zip', '')\n",
    "    data.append([file_name, spearman_cor])\n",
    "\n",
    "# Create a DataFrame with the collected data\n",
    "df = pd.DataFrame(data, columns=['File Name', 'Spearman Correlation'])\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team Name</th>\n",
       "      <th>Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Team MBZUAI-UNAM</td>\n",
       "      <td>0.831625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Team Pinealai</td>\n",
       "      <td>0.837163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>msiino</td>\n",
       "      <td>0.808586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Team INGEOTEC</td>\n",
       "      <td>0.808650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Team BpHigh</td>\n",
       "      <td>0.808866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Team VerbaNexAI Lab</td>\n",
       "      <td>0.819189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Team Fired_from_NLP</td>\n",
       "      <td>0.810334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LuisRamos07</td>\n",
       "      <td>0.822289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Team IITK</td>\n",
       "      <td>0.808445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Team NRK</td>\n",
       "      <td>0.832901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Team OZemi</td>\n",
       "      <td>0.805227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Team UAlbertaNLP</td>\n",
       "      <td>0.853192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Team Text Mining</td>\n",
       "      <td>0.720198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Team AAdaM</td>\n",
       "      <td>0.848436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Team YNUNLP2023</td>\n",
       "      <td>0.557246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Team MasonTigers</td>\n",
       "      <td>0.835603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Team YSP</td>\n",
       "      <td>0.819434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Team NLP_STR_teamS</td>\n",
       "      <td>0.809450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Team PALI</td>\n",
       "      <td>0.859576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Team NLP-LISAC</td>\n",
       "      <td>0.834584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Team KINLP</td>\n",
       "      <td>0.740003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Team HausaNLP</td>\n",
       "      <td>0.794372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Team Unknown</td>\n",
       "      <td>0.830615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Team WarwickNLP</td>\n",
       "      <td>0.842469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Team GIL-IIMAS UNAM</td>\n",
       "      <td>0.830448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Team UMBCLU</td>\n",
       "      <td>0.838050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Team team triplet</td>\n",
       "      <td>0.847886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Team king001</td>\n",
       "      <td>0.843086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Team NLP_Team1@SSN</td>\n",
       "      <td>0.835241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Roronoa_Zoro</td>\n",
       "      <td>0.809767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Team silp_nlp</td>\n",
       "      <td>0.844622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Team BITS Pilani</td>\n",
       "      <td>0.832374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Team SemanticCUETSync</td>\n",
       "      <td>0.822186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Team Sharif_STR</td>\n",
       "      <td>0.827404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Team Tu╠êbingen-CL</td>\n",
       "      <td>0.849975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Team CAILMD-23</td>\n",
       "      <td>0.823047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Team Name  Spearman Correlation\n",
       "0        Team MBZUAI-UNAM               0.831625\n",
       "1           Team Pinealai               0.837163\n",
       "2                   msiino              0.808586\n",
       "3           Team INGEOTEC               0.808650\n",
       "4             Team BpHigh               0.808866\n",
       "5     Team VerbaNexAI Lab               0.819189\n",
       "6     Team Fired_from_NLP               0.810334\n",
       "7              LuisRamos07              0.822289\n",
       "8               Team IITK               0.808445\n",
       "9                Team NRK               0.832901\n",
       "10             Team OZemi               0.805227\n",
       "11       Team UAlbertaNLP               0.853192\n",
       "12       Team Text Mining               0.720198\n",
       "13             Team AAdaM               0.848436\n",
       "14        Team YNUNLP2023               0.557246\n",
       "15       Team MasonTigers               0.835603\n",
       "16               Team YSP               0.819434\n",
       "17     Team NLP_STR_teamS               0.809450\n",
       "18              Team PALI               0.859576\n",
       "19         Team NLP-LISAC               0.834584\n",
       "20             Team KINLP               0.740003\n",
       "21          Team HausaNLP               0.794372\n",
       "22           Team Unknown               0.830615\n",
       "23        Team WarwickNLP               0.842469\n",
       "24    Team GIL-IIMAS UNAM               0.830448\n",
       "25            Team UMBCLU               0.838050\n",
       "26      Team team triplet               0.847886\n",
       "27           Team king001               0.843086\n",
       "28     Team NLP_Team1@SSN               0.835241\n",
       "29            Roronoa_Zoro              0.809767\n",
       "30          Team silp_nlp               0.844622\n",
       "31       Team BITS Pilani               0.832374\n",
       "32  Team SemanticCUETSync               0.822186\n",
       "33        Team Sharif_STR               0.827404\n",
       "34     Team Tu╠êbingen-CL               0.849975\n",
       "35         Team CAILMD-23               0.823047"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if 'File Name' column exists in the DataFrame\n",
    "if 'File Name' not in df.columns:\n",
    "    # Add 'File Name' column with default values\n",
    "    df['File Name'] = ''\n",
    "\n",
    "# Update the DataFrame to clean up the file names and rename the column\n",
    "df['File Name'] = df['File Name'].str.replace(r' - \\d+ output', '', regex=True)\n",
    "df.rename(columns={'File Name': 'Team Name'}, inplace=True)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from zipfile import ZipFile\n",
    "import os\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "\n",
    "\n",
    "# Redefine initial zip file path and extraction directory\n",
    "zip_file_path = './Semantic Textual Relatedness (STR) - SemEval 2024 Task 1 (Evaluation Phase)-16799-results-4.zip'\n",
    "extraction_dir = './output/'\n",
    "\n",
    "\n",
    "# Unzip the main file\n",
    "with ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extraction_dir)\n",
    "\n",
    "# Define the main folder path\n",
    "unzipped_contents = os.listdir(extraction_dir)\n",
    "main_folder = [d for d in unzipped_contents if not d.startswith('__')][0]\n",
    "main_folder_path = os.path.join(extraction_dir, main_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./Semantic Textual Relatedness (STR) - SemEval 2024 Task 1 (Evaluation Phase)-16799-results-4.zip'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List and filter the zip files that contain \"output\" in their names\n",
    "main_folder_contents = os.listdir(main_folder_path)\n",
    "output_zip_files_paths = [os.path.join(main_folder_path, f) for f in main_folder_contents if f.endswith('.zip') and 'output' in f.lower()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_folder_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "# Function to extract spearman_cor from scores.txt\n",
    "def extract_spearman_cor_from_scores(extracted_dir):\n",
    "    scores_path = os.path.join(extracted_dir, 'scores.txt')\n",
    "    try:\n",
    "        with open(scores_path, 'r') as file:\n",
    "            for line in file:\n",
    "                if 'spearman_cor' in line:\n",
    "                    return float(line.split(':')[-1].strip())\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "# Process each zip file\n",
    "for zip_path in output_zip_files_paths:\n",
    "    with ZipFile(zip_path, 'r') as zip_ref:\n",
    "        extracted_dir_path = zip_path.replace('.zip', '_extracted')\n",
    "        zip_ref.extractall(extracted_dir_path)\n",
    "    \n",
    "    spearman_cor = extract_spearman_cor_from_scores(extracted_dir_path)\n",
    "    file_name = os.path.basename(zip_path).replace('.zip', '').replace(r' - \\d+ output', '')\n",
    "    data.append([file_name, spearman_cor])\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data, columns=['Team Name', 'Spearman Correlation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team Name</th>\n",
       "      <th>Spearman Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Team Name, Spearman Correlation]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rank      Team Name  Spearman Correlation\n",
      "0     1  Tu╠êbingen-CL              0.837430\n",
      "1     2       HausaNLP              0.818939\n",
      "2     2      CAILMD-23              0.818939\n",
      "3     3           IITK              0.808445\n",
      "4     4            YSP              0.788130\n",
      "5     5    UAlbertaNLP              0.774964\n",
      "6     6         SATLab              0.774053\n",
      "7     7    MasonTigers              0.765988\n",
      "8     8            TSC              0.758157\n",
      "9     9       silp_nlp              0.316928\n"
     ]
    }
   ],
   "source": [
    "# from zipfile import ZipFile\n",
    "import os\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# Path to the uploaded zip file\n",
    "zip_file_path = \"./B4_eng.zip\"\n",
    "# Define a new extraction directory to start fresh\n",
    "# extraction_dir_fresh = './Output/'\n",
    "\n",
    "extraction_dir = './output/'\n",
    "\n",
    "\n",
    "# Unzip the main file\n",
    "with ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extraction_dir)\n",
    "\n",
    "# Define the main folder path\n",
    "unzipped_contents = os.listdir(extraction_dir)\n",
    "main_folder = [d for d in unzipped_contents if not d.startswith('__')][0]\n",
    "main_folder_path = os.path.join(extraction_dir, main_folder)\n",
    "\n",
    "# List and filter the zip files that contain \"output\" in their names\n",
    "main_folder_contents = os.listdir(main_folder_path)\n",
    "output_zip_files_paths = [os.path.join(main_folder_path, f) for f in main_folder_contents if f.endswith('.zip') and 'output' in f.lower()]\n",
    "\n",
    "# Initialize a list to store data\n",
    "data = []\n",
    "\n",
    "# Function to extract spearman_cor from scores.txt\n",
    "def extract_spearman_cor_from_scores(extracted_dir):\n",
    "    scores_path = os.path.join(extracted_dir, 'scores.txt')\n",
    "    try:\n",
    "        with open(scores_path, 'r') as file:\n",
    "            for line in file:\n",
    "                if 'spearman_cor' in line:\n",
    "                    return float(line.split(':')[-1].strip())\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "# Process each zip file\n",
    "for zip_path in output_zip_files_paths:\n",
    "    with ZipFile(zip_path, 'r') as zip_ref:\n",
    "        extracted_dir_path = zip_path.replace('.zip', '_extracted')\n",
    "        zip_ref.extractall(extracted_dir_path)\n",
    "    \n",
    "    spearman_cor = extract_spearman_cor_from_scores(extracted_dir_path)\n",
    "    file_name = os.path.basename(zip_path).replace('.zip', '').replace(r' - \\d+ output', '')\n",
    "    data.append([file_name, spearman_cor])\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data, columns=['Team Name', 'Spearman Correlation'])\n",
    "\n",
    "# Clean up team names and add ranking\n",
    "df['Team Name'] = df['Team Name'].str.replace(r' - \\d+ output', '', regex=True)\n",
    "df['Team Name'] = df['Team Name'].str.replace('team', '', case=False, regex=False).str.strip()\n",
    "df['Rank'] = df['Spearman Correlation'].rank(method='dense', ascending=False)\n",
    "df['Rank'] = df['Rank'].astype(int)  # Convert ranks to integers\n",
    "df_sorted = df.sort_values(by='Spearman Correlation', ascending=False).reset_index(drop=True)\n",
    "df_final = df_sorted[['Rank', 'Team Name', 'Spearman Correlation']]\n",
    "\n",
    "# Display the final DataFrame\n",
    "print(df_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final DataFrame to a CSV file\n",
    "csv_file_path = './TrackB/TrackB4_eng.csv'\n",
    "df_final.to_csv(csv_file_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./TrackC/TrackC4_eng.csv'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the final DataFrame to a CSV file\n",
    "csv_file_path = './TrackC/TrackC4_eng.csv'\n",
    "df_final.to_csv(csv_file_path, index=False)\n",
    "\n",
    "csv_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'gxps'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to convert \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to PDF. Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[43mconvert_oxps_to_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput.oxps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput.pdf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[31], line 5\u001b[0m, in \u001b[0;36mconvert_oxps_to_pdf\u001b[0;34m(input_file, output_file)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_oxps_to_pdf\u001b[39m(input_file, output_file):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 5\u001b[0m         \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgxps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-sDEVICE=pdfwrite\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-sOutputFile=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43moutput_file\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_file\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion successful: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/mambaforge/envs/datascience/lib/python3.9/subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    502\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m    503\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[0;32m--> 505\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    507\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[0;32m~/mambaforge/envs/datascience/lib/python3.9/subprocess.py:951\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[1;32m    947\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[1;32m    948\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m    949\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m--> 951\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[0;32m~/mambaforge/envs/datascience/lib/python3.9/subprocess.py:1821\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1819\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errno_num \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1820\u001b[0m         err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1821\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1822\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'gxps'"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "def convert_oxps_to_pdf(input_file, output_file):\n",
    "    try:\n",
    "        subprocess.run([\"gxps\", \"-sDEVICE=pdfwrite\", f\"-sOutputFile={output_file}\", input_file], check=True)\n",
    "        print(f\"Conversion successful: {output_file}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Failed to convert {input_file} to PDF. Error: {e}\")\n",
    "\n",
    "# Example usage\n",
    "convert_oxps_to_pdf(\"input.oxps\", \"output.pdf\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
